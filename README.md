ğŸ§  AI for Ingredient Classification
Flavor Fusion utilizes a Vision Transformer (ViT) model to classify food ingredients â€” specifically spices â€” directly from images. This forms the backbone of the system's ability to understand and reason about ingredients in a recipe context.

ğŸ—‚ï¸ What the Model Does
Classifies images of individual ingredients (e.g., turmeric, spinach, cardamom) into 52 distinct spice and ingredient categories

Helps power the broader flavor fusion logic by accurately identifying the ingredient type from a photo

ğŸ—ï¸ Architecture & Workflow
Base Model: google/vit-base-patch16-224 from Hugging Face Transformers

Image Processing: ViTImageProcessor used for resizing and normalizing input images

Transfer Learning: Final classification head is replaced with a custom linear layer for 52 classes

Training Setup:

Optimizer: AdamW

Scheduler: Linear Warmup + Decay

Loss: CrossEntropy

Dropout Regularization: 0.4

Input Transformations: Resize â†’ CenterCrop â†’ ToTensor

ğŸ‹ï¸ Dataset & Preprocessing
Custom Image Dataset organized in class-specific folders (ImageFolder format)

Dataset mounted from Google Drive and loaded with PyTorch Dataloaders

Train-test split: 80/20

Images are preprocessed using both torchvision.transforms and ViTImageProcessor

ğŸ” Inference Pipeline
Given a test image (e.g., Spinach_test.jpeg), the model:

Applies the same preprocessing as training

Performs a forward pass through the fine-tuned ViT model

Outputs the top predicted class from class_names (mapped from dataset)

ğŸ’¾ Model Persistence
Model state is saved as: /content/drive/MyDrive/pr dataset.pt

Can be reloaded for inference without retraining

