{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc224c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification,get_linear_schedule_with_warmup\n",
    "\n",
    "from PIL import Image\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import random_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linking my drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing and loading\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder('/content/drive/MyDrive/spices', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224',do_rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#control panel\n",
    "Batch_size=32#this states the size of each batch taken by the train\n",
    "Epochs=7#number of iterations\n",
    "Learning_rate=2e-5\n",
    "dp_rate=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model class\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self,n_classes,dp_rate):\n",
    "        super(classifier,self).__init__()\n",
    "        self.vit=ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "        self.dropout=nn.Dropout(dp_rate)\n",
    "        # The output layer should have n_classes, not n_classes + 1\n",
    "        self.out=nn.Linear(1000,n_classes)\n",
    "        self.num_classes = n_classes\n",
    "    def forward(self,inputs):\n",
    "        pooled_output=self.vit(inputs).logits\n",
    "        output=self.dropout(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing which is prior to capsuling it in a dataloader class\n",
    "class Preprocessing:\n",
    "  def __init__(self,data,transform,processor):\n",
    "    self.data=data\n",
    "    self.transform=transform\n",
    "    self.processor=processor\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self,idx):\n",
    "    image,label=self.data[idx]\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "      if self.transform:\n",
    "        image=self.transform(image)\n",
    "    inputs=self.processor(images=image,return_tensors=\"pt\")\n",
    "\n",
    "    return inputs['pixel_values'].squeeze(0),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9132d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataloader(data,transform,processor):\n",
    "  dl=Preprocessing(data,transform,processor)\n",
    "  return torch.utils.data.DataLoader(dl,batch_size=Batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing a train test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=Dataloader(train_data,transform,processor)\n",
    "test_loader=Dataloader(test_data,transform,processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e96e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing GPU\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacae9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model initialization\n",
    "model=classifier(52,dp_rate)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3707935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs,optim,scheduler\n",
    "EPOCHS=Epochs\n",
    "optimizer=AdamW(model.parameters(),lr=Learning_rate)\n",
    "total_steps=len(train_loader)*EPOCHS\n",
    "scheduler=get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=total_steps)\n",
    "loss_fn=nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model(inputs)\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "\n",
    "        loss = loss_fn(output, labels)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        num_batches += 1\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracy = correct_predictions / n_examples * 100\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test(model, test_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            _, preds = torch.max(output, dim=1)\n",
    "\n",
    "            loss = loss_fn(output, labels)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            num_batches += 1\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracy = correct_predictions / n_examples * 100\n",
    "    return avg_loss, accuracy,preds\n",
    "\n",
    "def train_model(model, train_loader, test_loader, loss_fn, optimizer, device, scheduler, n_examples_train, n_examples_test, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model, train_loader, loss_fn, optimizer, device, scheduler, len(train_data))\n",
    "        test_loss, test_acc, _ = test(model, test_loader, loss_fn, device, len(test_data)) # Modified line: unpacking the 3rd return value into '_' (ignore)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, test_loader, loss_fn, optimizer, device, scheduler, len(train_data), len(test_data), EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatgpt code(check it out later)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "# Load the model architecture\n",
    "model = classifier(52, dp_rate)  # Initialize your model\n",
    "model = model.to(device)  # Move to device\n",
    "\n",
    "# Load the model state dictionary (weights)\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/pr dataset.pt'))\n",
    "\n",
    "# Now, you should be able to set the model to evaluation mode\n",
    "model.eval()\n",
    "# Load the trained model\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads and preprocesses a single image.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)  # Apply the same transforms used during training\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    return inputs['pixel_values'].squeeze(0).to(device)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = '/content/drive/MyDrive/test/Spinach_test.jpeg'  # Replace with the actual path\n",
    "input_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor.unsqueeze(0))  # Add batch dimension\n",
    "    predicted_class_index = torch.argmax(output).item()\n",
    "\n",
    "# Interpret the prediction\n",
    "# Assuming you have a list of class labels called 'class_names'\n",
    "predicted_class_label = class_names[predicted_class_index]\n",
    "print(f\"Predicted class: {predicted_class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'/content/drive/MyDrive/pr dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac238e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('/content/drive/MyDrive/pr dataset.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
